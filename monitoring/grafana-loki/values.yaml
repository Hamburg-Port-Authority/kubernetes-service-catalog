loki:
  # -- Deployment mode lets you specify how to deploy Loki.
  # There are 3 options:
  # - SingleBinary: Loki is deployed as a single binary, useful for small installs typically without HA, up to a few tens of GB/day.
  # - SimpleScalable: Loki is deployed as 3 targets: read, write, and backend. Useful for medium installs easier to manage than distributed, up to a about 1TB/day.
  # - Distributed: Loki is deployed as individual microservices. The most complicated but most capable, useful for large installs, typically over 1TB/day.
  # There are also 2 additional modes used for migrating between deployment modes:
  # - SingleBinary<->SimpleScalable: Migrate from SingleBinary to SimpleScalable (or vice versa)
  # - SimpleScalable<->Distributed: Migrate from SimpleScalable to Distributed (or vice versa)
  # Note: SimpleScalable and Distributed REQUIRE the use of object storage.
  deploymentMode: SimpleScalable
  loki:
    containerSecurityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
    podSecurityContext:
      seccompProfile:
        type: RuntimeDefault
    # -- Limits config
    limits_config:
      retention_period: 192h
    # -- Storage config. Providing this will automatically populate all necessary storage configs in the templated config.
    storage:
      bucketNames:
        chunks: chunks
        ruler: ruler
        admin: admin
      type: 's3'
      s3:
        s3: null
        endpoint: https://minio.minio-loki
        region: 
        secretAccessKey: null
        accessKeyId: null
        s3ForcePathStyle: true
        insecure: true
        http_config:
          insecure_skip_verify: true
    schemaConfig:
      configs:
      - from: "2023-07-01"
        index:
          period: 24h
          prefix: loki_index_
        object_store: s3
        schema: v13
        store: tsdb
      # - from: "2023-07-01"
      #   store: tsdb
      #   object_store: s3
      #   schema: v13
      #   index:
      #     prefix: index_
      #     period: 24h
    
  serviceAccount:
    create: true
    automountServiceAccountToken: true
  monitoring:
    dashboards:
      enabled: true
      namespace: null
      labels:
        grafana_dashboard: "1"
    rules:
      enabled: true
      alerting: true
    serviceMonitor:
      enabled: true
      interval: 15s
      scrapeTimeout: null
      scheme: http
      metricsInstance:
        enabled: true
    selfMonitoring:
      enabled: false
      tenant:
        name: "self-monitoring"
        secretNamespace: "{{ .Release.Namespace }}"
      grafanaAgent:
        installOperator: false
        enableConfigReadAPI: false
    lokiCanary:
      enabled: true

  memberlist:
    service:
      publishNotReadyAddresses: true
  gateway:
    enabled: true
    replicas: 2
    resources:
      limits:
        cpu: 10m
        memory: 40Mi
      requests:
        cpu: 5m
        memory: 20Mi
    verboseLogging: true
    containerSecurityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app.kubernetes.io/component: gateway

  chunksCache:
    # -- Amount of memory allocated to chunks-cache for object storage (in MB).
    allocatedMemory: 2048
    # -- Resource requests and limits for the results-cache
    # By default a safe memory limit will be requested based on allocatedMemory value (floor (* 1.2 allocatedMemory)).
    resources:
      limits:
        cpu: 20m
        memory: 3Gi
      requests:
        cpu: 5m
        memory: 2500Mi
  resultsCache:  
    # -- Amount of memory allocated to results-cache for object storage (in MB).
    allocatedMemory: 256
    # -- Resource requests and limits for the results-cache
    # By default a safe memory limit will be requested based on allocatedMemory value (floor (* 1.2 allocatedMemory)).
    resources:
      limits:
        cpu: 20m
        memory: 400Mi
      requests:
        cpu: 5m
        memory: 100Mi
  
  sidecar:
    resources:
      limits:
        cpu: 50m
        memory: 100Mi
      requests:
        cpu: 5m
        memory: 85Mi
    securityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
  
  memcached:
    podSecurityContext :
      seccompProfile:
        type: RuntimeDefault
      fsGroup: 10001
      runAsGroup: 10001
      runAsNonRoot: true
      runAsUser: 10001
    containerSecurityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
  memcachedExporter:
    containerSecurityContext:
      seccompProfile:
        type: RuntimeDefault
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
    
    resources:
      limits:
        cpu: 10m
        memory: 40Mi
      requests:
        cpu: 5m
        memory: 20Mi

  write:
    resources:
      limits:
        cpu: 100m
        memory: 800Mi
      requests:
        cpu: 30m
        memory: 300Mi
    topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app.kubernetes.io/component: write

  read:
    resources:
      limits:
        cpu: 100m
        memory: 500Mi
      requests:
        cpu: 25m
        memory: 250Mi
    topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app.kubernetes.io/component: read

  backend:
    replicas: 3
    persistence:
      enableStatefulSetAutoDeletePVC: true
      size: 10Gi
    resources:
      limits:
        cpu: 50m
        memory: 400Mi
      requests:
        cpu: 20m
        memory: 250Mi
    topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app.kubernetes.io/component: backend
  lokiCanary:
    resources:
      limits:
        cpu: 20m
        memory: 40Mi
      requests:
        cpu: 10m
        memory: 40Mi